# Introduction
- **Goal**: Improve model performance without altering the original model weights.
- **Contrast with Prompt Engineering**:
  - **Prompt Engineering**:
    - Manually crafting prompts to guide the model.
    - Can be time-consuming and may not always achieve desired results.
  - **Prompt Tuning**:
    - Adds trainable "soft prompts" to the input.
    - Leverages supervised learning to optimize the soft prompts for the specific task.

---

# Soft Prompts
- **Definition**:
  - A set of trainable tokens prepended to the input text.
  - Have the same length as the embedding vectors of input tokens.
- **Key Characteristics**:
  - **Virtual Tokens**:
    - Not fixed words; can take on any value within the embedding space.
    - Learned during the training process.
- **Training**:
  - **Frozen Model Weights**: The LLM's weights remain unchanged.
  - **Soft Prompt Optimization**: Only the embedding vectors of the soft prompt are updated during training.
![image](https://github.com/user-attachments/assets/c20e3dd3-006a-4fb1-a528-28eb90c4e96d)

---

## Full Fine-Tuning vs Soft Prompts
- In full fine-tuning, the weights of the large language model are updated during supervised learning.
- In contrast, with prompt tuning, the weights of the large language model are frozen, and the underlying model does not get updated.
- Instead, the embedding vectors of the soft prompt are updated over time to optimize the model's completion of the prompt.
- Prompt tuning is a very parameter-efficient strategy because only a few parameters are being trained, in contrast with the millions to billions of parameters in full fine-tuning.
- You can train a different set of soft prompts for each task and then easily swap them out at inference time.
![image](https://github.com/user-attachments/assets/fb1d1b8b-d644-49da-bceb-9aaaa1c52bb6)

# Advantages
- **Parameter Efficiency**:
  - Trains only a small number of parameters compared to full fine-tuning.
- **Flexibility**:
  - Easily switch between tasks by swapping out the learned soft prompts.
- **Minimal Storage**:
  - Soft prompts are small in size, requiring minimal disk storage.

# Performance
- **Comparable to Full Fine-Tuning**:
  - Prompt tuning doesn't perform as well as full fine-tuning for smaller LLMs.
  - For larger models (e.g., 10 billion parameters), prompt tuning can achieve performance comparable to full fine-tuning on many tasks.
- **Superior to Prompt Engineering**:
  - Offers significant performance improvements over traditional prompt engineering.
- **Limited Interpretability**:
  - Learned soft prompt tokens may not directly correspond to human-readable words or phrases.
  - Analyzing the nearest neighbor tokens can provide insights into the learned representations.
![image](https://github.com/user-attachments/assets/3145b544-0fb4-471e-9eff-cd949f9a7b4a)

---

# PEFT Conclusion
- **Effective and Efficient Fine-Tuning Method**:
  - Reduces computational cost and memory requirements.
  - Enables efficient adaptation of LLMs to various tasks.
- **LoRA and Prompt Tuning** enable fine-tuning of models with the potential for improved performance on tasks while using much less compute than full fine-tuning methods.
- **LoRA** is the method that is broadly used in practice.
- **QLoRA**: LoRA can also be combined with quantization techniques to further reduce memory footprint.
- In practice, **PEFT** is used heavily to minimize compute and memory resources, ultimately reducing the cost of fine-tuning, allowing you to make the most of your compute budget and speed up your development process.
![image](https://github.com/user-attachments/assets/7117ef61-4790-43a5-b7a6-9b41043cf136)

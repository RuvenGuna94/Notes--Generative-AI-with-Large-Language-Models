# Introduction
- **Goal**: Improve model performance without altering the original model weights.
- **Contrast with Prompt Engineering**:
  - **Prompt Engineering**:
    - Manually crafting prompts to guide the model.
    - Can be time-consuming and may not always achieve desired results.
  - **Prompt Tuning**:
    - Adds trainable "soft prompts" to the input.
    - Leverages supervised learning to optimize the soft prompts for the specific task.

---

# Soft Prompts
- **Definition**:
  - A set of trainable tokens prepended to the input text.
  - Have the same length as the embedding vectors of input tokens.
- **Key Characteristics**:
  - **Virtual Tokens**:
    - Not fixed words; can take on any value within the embedding space.
    - Learned during the training process.
- **Training**:
  - **Frozen Model Weights**: The LLM's weights remain unchanged.
  - **Soft Prompt Optimization**: Only the embedding vectors of the soft prompt are updated during training.

---



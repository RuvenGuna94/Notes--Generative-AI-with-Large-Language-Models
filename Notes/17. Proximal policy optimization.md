# Considerations for Deploying LLMs

### Functionality in Deployment
- How fast do you need your model to generate completions?
- What compute budget is available?
- Are you willing to trade performance for inference speed or lower storage?
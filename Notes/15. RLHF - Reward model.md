# Training the Reward Model

## Purpose
- The reward model replaces human labelers once it has been trained.
- It automatically selects the preferred completion during the RLHF process.

## Reward Model as a Language Model
- The reward model is typically a language model, trained using supervised learning on the pairwise comparison data from human labelers (e.g., BERT).
- The model learns to favor the human-preferred completion and minimizes the difference between the reward values for different completions.



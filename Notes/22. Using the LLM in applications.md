# Key Issues with LLMs

1. **Knowledge Cutoff**
   - LLMs lack knowledge of events after their training period.
   - **Example**: A model trained in early 2022 might incorrectly state that Boris Johnson is the British Prime Minister.

2. **Math Struggles**
   - LLMs don't perform mathematical operations but predict the next best token.
   - **Example**: They may provide approximate but incorrect answers for division problems.

3. **Hallucination**
   - LLMs may generate information even when itâ€™s incorrect or fabricated.
   - **Example**: Inventing a nonexistent plant, like the "Martian Dunetree."

---

## Solution: Connecting LLMs to External Data Sources

- External data can improve accuracy and relevance during inference.
- **Example Tools**: LangChain for orchestration and connection to APIs.

---
# Key Issues with LLMs

1. **Knowledge Cutoff**
   - LLMs lack knowledge of events after their training period.
   - **Example**: A model trained in early 2022 might incorrectly state that Boris Johnson is the British Prime Minister.

2. **Math Struggles**
   - LLMs don't perform mathematical operations but predict the next best token.
   - **Example**: They may provide approximate but incorrect answers for division problems.

3. **Hallucination**
   - LLMs may generate information even when itâ€™s incorrect or fabricated.
   - **Example**: Inventing a nonexistent plant, like the "Martian Dunetree."

---

## Solution: Connecting LLMs to External Data Sources

- External data can improve accuracy and relevance during inference.
- **Example Tools**: LangChain for orchestration and connection to APIs.
![image](https://github.com/user-attachments/assets/a25f4178-9176-4259-89a4-0260fef5a5e2)

---

# Retrieval Augmented Generation (RAG) Framework

### 1. Purpose
- Overcomes knowledge cutoff and hallucination issues.
- Provides access to external data sources at inference time.
- A framework (not specific technology) enabling LLMs to access unseen data during training.

### 2. Benefits
- Avoids expensive retraining.
- Enables the model to access up-to-date, proprietary, or context-specific data.


### 3. How It Works
- **Retriever** connects user input to external data sources:
  - **Query Encoder**: Encodes the user prompt into a query format.
  - **External Data Source**: Stores information (e.g., vector stores, databases, or documents).
- Relevant data is retrieved, combined with the user prompt, and passed to the LLM.
![image](https://github.com/user-attachments/assets/ac390094-b471-4a27-978d-2309e7f07c78)

### 4. Example Use Case: Legal Discovery
- A lawyer queries court filings to find information about a plaintiff in a specific case.
- The retriever identifies relevant documents and expands the prompt with new information.
- The LLM generates an accurate, context-aware response.
![image](https://github.com/user-attachments/assets/79547825-aefd-45e1-ad9e-7e1c43f75e6e)
![image](https://github.com/user-attachments/assets/36beb510-6b8a-4484-8708-bd485c22a704)

---

# Advantages of RAG

1. **Access to Local Documents**
   - Private wikis, expert systems, or proprietary knowledge bases.

2. **Internet Access**
   - Enables real-time data retrieval, e.g., Wikipedia.

3. **Database Interaction**
   - Encodes the user prompt as a SQL query, allowing interaction with databases.

4. **Vector Stores**
   - Contains vector representations of text.
   - Enables fast and efficient search based on similarity (efficient semantic search using embedding vectors).

---

# Key Considerations

### 1. Context Window Limitations
- Most data sources exceed the token limit (general limit of 1000+ tokens).
- Data is divided into smaller chunks that fit within the context window.
![image](https://github.com/user-attachments/assets/394d08d5-febf-45bf-9737-f05a8e57cafc)

### 2. Data Format
- Data must be structured for efficient retrieval.
- Embedding vectors allow semantically related text to be identified via similarity measures like cosine similarity.
- RAG methods process external data through LLMs to create embedding vectors, stored in **vector stores** for fast searching and efficient identification of related text.
![image](https://github.com/user-attachments/assets/45915f47-69ed-4577-aa70-f82015e21206)
![image](https://github.com/user-attachments/assets/17f2948e-0bdd-4066-8a9e-51ff1f8ace37)

### 3. Vector Databases
- **Definition**: A specialized implementation of vector stores where each vector is associated with a unique key.
- **Purpose**: Enables efficient storage, retrieval, and contextual reference of embeddings.

#### Key Features:
1. **Key Association**
   - Each vector is linked to a specific key, like a document ID or source identifier.
   - Facilitates traceability and precise retrieval of the original source.

2. **Citation Inclusion**
   - Text generated by RAG can include citations pointing to the source document.
   - **Example**: "This information is from [Document A]."

---
# Impact on User Experience

- Overcomes internal knowledge limits.
- Avoids hallucination by grounding responses in real data.
- Improves relevance, accuracy, and reliability of model completions.

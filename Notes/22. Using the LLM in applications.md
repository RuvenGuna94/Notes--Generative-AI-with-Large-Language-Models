# Key Issues with LLMs

1. **Knowledge Cutoff**
   - LLMs lack knowledge of events after their training period.
   - **Example**: A model trained in early 2022 might incorrectly state that Boris Johnson is the British Prime Minister.

2. **Math Struggles**
   - LLMs don't perform mathematical operations but predict the next best token.
   - **Example**: They may provide approximate but incorrect answers for division problems.

3. **Hallucination**
   - LLMs may generate information even when itâ€™s incorrect or fabricated.
   - **Example**: Inventing a nonexistent plant, like the "Martian Dunetree."

---

## Solution: Connecting LLMs to External Data Sources

- External data can improve accuracy and relevance during inference.
- **Example Tools**: LangChain for orchestration and connection to APIs.

---

# Retrieval Augmented Generation (RAG) Framework

### 1. Purpose
- Overcomes knowledge cutoff and hallucination issues.
- Provides access to external data sources at inference time.
- A framework (not specific technology) enabling LLMs to access unseen data during training.

### 2. Benefits
- Avoids expensive retraining.
- Enables the model to access up-to-date, proprietary, or context-specific data.

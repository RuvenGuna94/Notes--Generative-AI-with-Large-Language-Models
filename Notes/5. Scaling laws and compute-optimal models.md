# Scaling Laws

- **Increasing dataset size**: More data can improve model performance.
- **Increasing model parameters**: Larger models can learn more complex patterns.
- **Compute budget limitations**: Consider available GPUs and training time.

---

## Unit of Compute
- **PetaFLOP per second day**:
  - One quadrillion floating-point operations per second for 24 hours.
  - Approximately equivalent to 8 NVIDIA V100 GPUs running at full capacity for one day.
  - More powerful processors can reduce the number of chips required.
  - For example, two NVIDIA A100 GPUs provide equivalent compute to the eight V100 chips.

## Scaling Laws and Compute Budget
- **Relationship between compute budget, model size, and dataset size**:
  - Larger models and datasets generally require more compute.
  - Power-law relationship between compute budget and model performance.
  - Compute budget is often a hard constraint.

---



1. **Infrastructure Layer**:
   - Provides the foundation for compute, storage, and networking.
   - Can be on-premises or cloud-based (on-demand, pay-as-you-go).
   - Must be scalable to meet real-time or near-real-time inference needs.

2. **Language Models**:
   - Includes foundation models and task-specific fine-tuned models.
   - Deployed on suitable infrastructure tailored to your latency and resource needs.

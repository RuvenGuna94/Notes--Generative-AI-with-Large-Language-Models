1. **Infrastructure Layer**:
   - Provides the foundation for compute, storage, and networking.
   - Can be on-premises or cloud-based (on-demand, pay-as-you-go).
   - Must be scalable to meet real-time or near-real-time inference needs.

2. **Language Models**:
   - Includes foundation models and task-specific fine-tuned models.
   - Deployed on suitable infrastructure tailored to your latency and resource needs.

3. **External Data Integration**:
   - Use retrieval-augmented generation (RAG) to fetch information from external sources.
   - Augments the model's static context window for more dynamic and relevant completions.
